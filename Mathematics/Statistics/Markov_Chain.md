---
aliases:
has_id_wikidata: Q176645
named_after: "[[_Standards/WikiData/WD~Andrey_Markov,176659]]"
subclass_of:
  - "[[_Standards/WikiData/WD~mathematical_model,486902]]"
  - "[[_Standards/WikiData/WD~Markov_process,2221775]]"
instance_of: "[[_Standards/WikiData/WD~statistical_model,3284399]]"
maintained_by_WikiProject: "[[_Standards/WikiData/WD~WikiProject_Mathematics,8487137]]"
OmegaWiki_Defined_Meaning: "382987"
image: http://commons.wikimedia.org/wiki/Special:FilePath/Markovkate%2001.svg
UMLS_CUI: C0024828
MeSH_tree_code:
  - E05.318.740.600.500
  - E05.318.740.996.500
  - G17.830.500
  - N05.715.360.750.625.500
  - N05.715.360.750.770.500
  - N06.850.520.830.600.500
  - N06.850.520.830.996.500
Commons_category: Markov chains
---

# [[Markov_Chain]] 

#is_/same_as :: [[WD~Markov_chain,176645]] 

## #has_/text_of_/abstract 

> In probability theory and statistics, a Markov chain or Markov process 
> is a stochastic process describing a sequence of possible events 
> in which the probability of each new event 
> depends **only on the state attained in the previous event**. 
> 
> Informally, this may be thought of as, 
> "What happens next depends only on the state of affairs now." 
> 
> A countably infinite sequence, in which the chain moves state at discrete time steps, 
> gives a discrete-time Markov chain (DTMC). 
> 
> A continuous-time process is called a continuous-time Markov chain (CTMC). 
> Markov processes are named in honor of the Russian mathematician Andrey Markov.
>
> Markov chains have many applications as statistical models of real-world processes. 
> They provide the basis for general stochastic simulation methods 
> known as Markov chain Monte Carlo, 
> which are used for simulating sampling from complex probability distributions, 
> and have found application in areas including Bayesian statistics, biology, chemistry, economics, finance, information theory, physics, signal processing, and speech processing.
>
> The adjectives Markovian and Markov are used 
> to describe something that is related to a Markov process.
>
> [Wikipedia](https://en.wikipedia.org/wiki/Markov%20chain) 


## Confidential Links & Embeds: 

### #is_/same_as :: [[/_Standards/Mathematics/Statistics/Markov_Chain|Markov_Chain]] 

### #is_/same_as :: [[/_public/Mathematics/Statistics/Markov_Chain.public|Markov_Chain.public]] 

### #is_/same_as :: [[/_internal/Mathematics/Statistics/Markov_Chain.internal|Markov_Chain.internal]] 

### #is_/same_as :: [[/_protect/Mathematics/Statistics/Markov_Chain.protect|Markov_Chain.protect]] 

### #is_/same_as :: [[/_private/Mathematics/Statistics/Markov_Chain.private|Markov_Chain.private]] 

### #is_/same_as :: [[/_personal/Mathematics/Statistics/Markov_Chain.personal|Markov_Chain.personal]] 

### #is_/same_as :: [[/_secret/Mathematics/Statistics/Markov_Chain.secret|Markov_Chain.secret]] 

