---
aliases:
- Cadea de Markov
- cadeia de Markov
- cadeias de Markov
- cadena de Markov
- cadena de Màrkov
- Cadena de Márkov
- chaîne de Markov
- Lanț Markov
- Markov chain
- Markov kate
- Markov zinciri
- Markov-a ĉeno
- Markov-keten
- Markov-keðja
- Markov-kjede
- Markov-kæde
- Markov-lánc
- Markova ķēde
- Markovi ahel
- Markovin ketju
- Markovkedja
- Markovketting
- Markovkjede
- Markovljev lanac
- Markovo grandinė
- Markovův řetězec
- Markow-Kette
- processo markoviano
- Rantai Markov
- Ranté Markov
- Slabhra Markov
- veriga Markova
- Xích Markov
- Zinxhirët e Markovit
- łańcuch Markowa
- Αλυσίδα Μαρκόφ
- Ланци Маркова
- ланцюги Маркова
- Маркавы ланцуг
- Марковска верига
- цепь Маркова
- Մարկովի շղթա
- שרשרת מרקוב
- زنجیره مارکوف
- سلسلة ماركوف
- مارکوو زنجیر
- ลูกโซ่มาร์คอฟ
- マルコフ連鎖
- 馬可夫鏈
- 馬爾可夫過程
- 马尔可夫链
- 마르꼬브사슬
- 마르코프 연쇄
has_id_wikidata: Q176645
named_after: '[[_Standards/WikiData/WD~Andrey_Markov,176659]]'
subclass_of:
- '[[_Standards/WikiData/WD~mathematical_model,486902]]'
- '[[_Standards/WikiData/WD~Markov_process,2221775]]'
instance_of: '[[_Standards/WikiData/WD~statistical_model,3284399]]'
maintained_by_WikiProject: '[[_Standards/WikiData/WD~WikiProject_Mathematics,8487137]]'
OmegaWiki_Defined_Meaning: 382987
image: http://commons.wikimedia.org/wiki/Special:FilePath/Markovkate%2001.svg
UMLS_CUI: C0024828
MeSH_tree_code:
- E05.318.740.600.500
- E05.318.740.996.500
- G17.830.500
- N05.715.360.750.625.500
- N05.715.360.750.770.500
- N06.850.520.830.600.500
- N06.850.520.830.996.500
Commons_category: Markov chains
dv_has_:
  name_:
    af: Markovketting
    ar: سلسلة ماركوف
    ast: Cadena de Márkov
    be_tarask: Маркавы ланцуг
    bg: Марковска верига
    ca: cadena de Màrkov
    cs: Markovův řetězec
    da: Markov-kæde
    de: Markow-Kette
    el: Αλυσίδα Μαρκόφ
    en: Markov chain
    en_ca: Markov chain
    en_gb: Markov chain
    en-us: Markov chain
    eo: Markov-a ĉeno
    es: cadena de Markov
    et: Markovi ahel
    eu: Markov kate
    fa: زنجیره مارکوف
    fi: Markovin ketju
    fr: chaîne de Markov
    ga: Slabhra Markov
    gl: Cadea de Markov
    he: שרשרת מרקוב
    hr: Markovljev lanac
    hu: Markov-lánc
    hy: Մարկովի շղթա
    id: Rantai Markov
    is: Markov-keðja
    it: processo markoviano
    ja: マルコフ連鎖
    ko: 마르코프 연쇄
    ko-kp: 마르꼬브사슬
    lt: Markovo grandinė
    lv: Markova ķēde
    nb: Markovkjede
    nl: Markov-keten
    nn: Markov-kjede
    pl: łańcuch Markowa
    pt: cadeias de Markov
    pt_br: cadeia de Markov
    ro: Lanț Markov
    ru: цепь Маркова
    sh: Markovljev lanac
    sl: veriga Markova
    sq: Zinxhirët e Markovit
    sr: Ланци Маркова
    su: Ranté Markov
    sv: Markovkedja
    th: ลูกโซ่มาร์คอฟ
    tr: Markov zinciri
    uk: ланцюги Маркова
    ur: مارکوو زنجیر
    vi: Xích Markov
    yue: 馬可夫鏈
    zh: 马尔可夫链
    zh_cn: 马尔可夫链
    zh_hans: 马尔可夫链
    zh_hant: 馬爾可夫過程
---
# [[Markov_Chain]] 

#is_/same_as :: [[WD~Markov_chain,176645]] 

## #has_/text_of_/abstract 

> In probability theory and statistics, a Markov chain or Markov process 
> is a stochastic process describing a sequence of possible events 
> in which the probability of each new event 
> depends **only on the state attained in the previous event**. 
> 
> Informally, this may be thought of as, 
> "What happens next depends only on the state of affairs now." 
> 
> A countably infinite sequence, in which the chain moves state at discrete time steps, 
> gives a discrete-time Markov chain (DTMC). 
> 
> A continuous-time process is called a continuous-time Markov chain (CTMC). 
> Markov processes are named in honor of the Russian mathematician Andrey Markov.
>
> Markov chains have many applications as statistical models of real-world processes. 
> They provide the basis for general stochastic simulation methods 
> known as Markov chain Monte Carlo, 
> which are used for simulating sampling from complex probability distributions, 
> and have found application in areas including Bayesian statistics, biology, chemistry, economics, finance, information theory, physics, signal processing, and speech processing.
>
> The adjectives Markovian and Markov are used 
> to describe something that is related to a Markov process.
>
> [Wikipedia](https://en.wikipedia.org/wiki/Markov%20chain) 


## Confidential Links & Embeds: 

### #is_/same_as :: [[/_Standards/Mathematics/Statistics/Markov_Chain|Markov_Chain]] 

### #is_/same_as :: [[/_public/Mathematics/Statistics/Markov_Chain.public|Markov_Chain.public]] 

### #is_/same_as :: [[/_internal/Mathematics/Statistics/Markov_Chain.internal|Markov_Chain.internal]] 

### #is_/same_as :: [[/_protect/Mathematics/Statistics/Markov_Chain.protect|Markov_Chain.protect]] 

### #is_/same_as :: [[/_private/Mathematics/Statistics/Markov_Chain.private|Markov_Chain.private]] 

### #is_/same_as :: [[/_personal/Mathematics/Statistics/Markov_Chain.personal|Markov_Chain.personal]] 

### #is_/same_as :: [[/_secret/Mathematics/Statistics/Markov_Chain.secret|Markov_Chain.secret]] 

